---
title: 3.4 欧几里得空间
createTime: 2025/11/12 17:36:48
permalink: /course/9jg1yxu7/
---

## 一、向量内积

**定义** 设$\alpha,\beta \in \mathbb{R}^n$，则$\alpha$与$\beta$的**内积**定义为：
$$(\alpha,\beta) = a_1b_1 + a_2b_2 + \dots + a_nb_n$$

**矩阵乘法表示**：

1. $\alpha,\beta$为列向量：$(\alpha,\beta) = \alpha^T\beta = \beta^T\alpha$
2. $\alpha,\beta$为行向量：$(\alpha,\beta) = \alpha\beta^T = \beta\alpha^T$

**性质3.4.1**：

1. 对称性：$(\alpha,\beta) = (\beta,\alpha)$
2. 线性性：
   $$\left( \sum_{i=1}^s k_i\alpha_i,\ \beta \right) = \sum_{i=1}^s k_i(\alpha_i,\beta)$$
   $$\left( \sum_{i=1}^s k_i\alpha_i,\ \sum_{j=1}^t l_j\beta_j \right) = \sum_{i=1}^s \sum_{j=1}^t k_il_j(\alpha_i,\beta_j)$$
3. 正定性：$(\alpha,\alpha) \geq 0$，当且仅当$\alpha=0$时取等号

### **定义3.4.2**

定义了内积的$\mathbb{R}^n$称为**欧几里得空间**。

## 二、长度

### **定义3.4.3**

向量$\alpha$的**长度**为：

$$|\alpha| = \sqrt{(\alpha,\alpha)}$$

**注意**：

1. $\alpha \neq 0 \implies |\alpha| \neq 0$
2. $|\alpha|=1 \implies \alpha$是**单位向量**
3. $\alpha \neq 0$时，$\frac{1}{|\alpha|}\alpha$是$\alpha$的**单位化**向量

### **定理3.4.1（ ==柯西-施瓦茨公式== ）**

$$|(\alpha,\beta)| \leq |\alpha||\beta|$$

**证明**：

1. 若$\beta=0$，显然成立
2. 若$\beta \neq 0$，对任意$x \in \mathbb{R}$，有$(\alpha+x\beta,\alpha+x\beta) \geq 0$，展开得：
  $$(\beta,\beta)x^2 + 2(\alpha,\beta)x + (\alpha,\alpha) \geq 0$$
  二次函数恒非负，故判别式$\Delta = 4(\alpha,\beta)^2 - 4(\alpha,\alpha)(\beta,\beta) \leq 0$，即$(\alpha,\beta)^2 \leq (\alpha,\alpha)(\beta,\beta)$，开方得证。

### **定义3.4.4**

若$(\alpha,\beta)=0$，则称$\alpha$与$\beta$**正交**，记$\alpha \perp \beta$
（$0$与任一向量正交）

**例**：设$A \in \mathbb{R}^{m \times n}$，则对$\forall \alpha \in R(A^T)$与$\forall \beta \in N(A)$，有$\alpha \perp \beta$。
**证明**：$AX=0 \implies \begin{bmatrix}\alpha_1^T\\\vdots\\\alpha_m^T\end{bmatrix}X=0 \implies (\alpha_i,X)=0$，故$(\alpha,X)=0$。

**性质**：

1. 三角不等式：$|\alpha+\beta| \leq |\alpha| + |\beta|$
   **证明**：
   $$
   |\alpha+\beta|^2 = (\alpha+\beta,\alpha+\beta) =
   |\alpha|^2 + 2(\alpha,\beta) + |\beta|^2 \leq |\alpha|^2 + 2|\alpha||\beta| + |\beta|^2 = (|\alpha|+|\beta|)^2
   $$
2. 勾股定理：若$\alpha \perp \beta$，则$|\alpha+\beta|^2 = |\alpha|^2 + |\beta|^2$

## 三、标准正交基

### **定义3.4.6**

设 $\alpha_1,\dots,\alpha_m$ 是欧氏空间$V$中$m$个非零向量，若对 $\forall i \neq j$ ，
有 $(\alpha_i,\alpha_j)=0$ ，则 $\alpha_1,\dots,\alpha_m$ 是 ==**正交向量组**== ；若同时满足 $|\alpha_1|=\dots=|\alpha_m|=1$ ，则称为==**标准正交向量组**==。

### **定理3.4.2**

正交向量组线性无关。

### **定理3.4.3**

设 $V$ 是欧氏空间，$\alpha_1,\dots,\alpha_m$ 是 $V$ 中线性无关向量组，则 $V$ 中存在标准正交向量组
$\eta_1,\dots,\eta_m$ ，使得 $\{ \alpha_1,\dots,\alpha_k \} \cong \{ \eta_1,\dots,\eta_k \}\ (k=1,\dots,m)$ （等价关系）。

## 四、Schmidt正交化方法（核心：“投影”）

> [!IMPORTANT]
>

已知$\alpha_1,\alpha_2,\alpha_3$线性无关，步骤如下：

1. **正交化**：
   $$\beta_1 = \alpha_1$$
   $$\beta_2 = \alpha_2 - \frac{(\alpha_2,\beta_1)}{(\beta_1,\beta_1)}\beta_1$$
   $$\beta_3 = \alpha_3 - \frac{(\alpha_3,\beta_2)}{(\beta_2,\beta_2)}\beta_2 - \frac{(\alpha_3,\beta_1)}{(\beta_1,\beta_1)}\beta_1$$

   > [!NOTE]
   > 更高维数的公式形式相同：
   > $$\beta_n = \alpha_n - \sum_{i = 1}^{n - 1} \frac{(\alpha_n, \beta_i)}{(\beta_i, \beta_i)}\beta_i$$
2. **单位化**：
   $$\eta_i = \frac{1}{|\beta_i|}\beta_i\ (i=1,2,3)$$
则$\eta_1,\eta_2,\eta_3$是标准正交向量组。

### **定义3.4.7**

由标准正交向量组构成的基称为**标准正交基**。

**例**：欧氏空间$\mathbb{R}^n$的自然基$\varepsilon_1,\dots,\varepsilon_n$是标准正交基。

### **定理3.4.4**

设 $V \subseteq \mathbb{R}^n$ 是欧氏空间且 $V \neq \{0\}$ ，则 $V$ 一定存在标准正交基。

## 五、正交矩阵

若标准正交基 $\alpha_1,\dots,\alpha_n$ 到 $\beta_1,\dots,\beta_n$ 的过渡矩阵为 $A$ ，则 $A^TA = I$（ $A$ 为**正交矩阵**）。

**证明**：
由$[\beta_1\ \dots\ \beta_n] = [\alpha_1\ \dots\ \alpha_n]A$，且$\alpha_1,\dots,\alpha_n$是标准正交基，故：

$$
(\beta_i,\beta_j) = \left( \sum_{k=1}^n a_{ki}\alpha_k,\ \sum_{l=1}^n a_{lj}\alpha_l \right) =
\sum_{k=1}^n \sum_{l=1}^n a_{ki}a_{lj}(\alpha_k,\alpha_l) = \sum_{k=1}^n a_{ki}a_{kj} = (A^TA)_{ij}
$$

因 $\beta_1,\dots,\beta_n$ 是标准正交基，故 $(\beta_i,\beta_j)=\begin{cases}1,\ i=j\\0,\ i \neq j\end{cases}$ ，即 $A^TA=I$ 。

## 六、正交分解（QR分解）

**例3.4.7** 设 $A \in \mathbb{R}^{n \times n}$ 可逆，则 $A$ 可分解为 $A=QR$ ，其中 $Q$ 是正交矩阵， $R$ 是可逆上三角矩阵。

**证明**：
设 $A=[\alpha_1\ \dots\ \alpha_n]$ ，对 $\alpha_1,\dots,\alpha_n$ 做Schmidt正交化：

1. 正交化：
   $$\beta_1 = \alpha_1$$
   $$\beta_2 = \alpha_2 - \frac{(\alpha_2,\beta_1)}{(\beta_1,\beta_1)}\beta_1$$
   $$\vdots$$
   $$\beta_n = \alpha_n - \sum_{i=1}^{n-1} \frac{(\alpha_n,\beta_i)}{(\beta_i,\beta_i)}\beta_i$$

2. 单位化：$\eta_i = \frac{1}{|\beta_i|}\beta_i$，则 $\beta_i = |\beta_i|\eta_i$。

将 $\alpha_i$ 用 $\eta_1,\dots,\eta_i$ 表示，可得：

$$
A = [\eta_1\ \dots\ \eta_n]
\begin{bmatrix}|\beta_1|&*&\dots&*\\
0&|\beta_2|&\dots&*\\\vdots&\vdots&&
\vdots\\0&0&\dots&|\beta_n|
\end{bmatrix}
$$

其中 $Q=[\eta_1\ \dots\ \eta_n]$ （正交矩阵）， $R$ 是上三角矩阵（对角线元素 $|\beta_i| \neq 0$ ，故可逆）。

---

## 补充

### **题目（习题三.36）**

设 $\alpha_1, \ldots, \alpha_m$ 是欧氏空间中的一组向量，令

$$
G = \begin{bmatrix}
(\alpha_1, \alpha_1) & \cdots & (\alpha_1, \alpha_m) \\
\vdots & \ddots & \vdots \\
(\alpha_m, \alpha_1) & \cdots & (\alpha_m, \alpha_m)
\end{bmatrix}
$$

即 $G = [\langle \alpha_i, \alpha_j \rangle]_{m \times m}$，称为 **Gram 矩阵**。

**求证**：$\alpha_1, \ldots, \alpha_m$ 线性无关 $\iff G$ 可逆。

---

### **证明**

#### **（$\Leftarrow$）若 $G$ 可逆，则 $\alpha_1,\dots,\alpha_m$ 线性无关**

假设

$$
k_1\alpha_1 + k_2\alpha_2 + \cdots + k_m\alpha_m = 0
$$

对任意 $\alpha_i$ 做内积，得

$$
\left( \alpha_i, \sum_{j=1}^m k_j \alpha_j \right) = 0
\quad \Rightarrow \quad
\sum_{j=1}^m k_j (\alpha_i, \alpha_j) = 0
$$

对每个 $i = 1, 2, \ldots, m$ 成立，因此得到线性方程组：

$$
\sum_{j=1}^m k_j (\alpha_i, \alpha_j) = 0, \quad i = 1, \ldots, m
$$

以 $k_j$ 为未知数，$(\alpha_i, \alpha_j)$ 为系数，记作矩阵形式：
$$
G \mathbf{k} = \mathbf{0}, \quad \text{其中 } \mathbf{k} = \begin{bmatrix} k_1 \\ \vdots \\ k_m \end{bmatrix}
$$

由于 $G$ 可逆，故 $G \mathbf{k} = \mathbf{0}$ 仅有零解，即
$$
k_1 = k_2 = \cdots = k_m = 0
$$

所以 $\alpha_1, \ldots, \alpha_m$ 线性无关。

---

#### **（$\Rightarrow$）若 $\alpha_1,\dots,\alpha_m$ 线性无关，则 $G$ 可逆**

考虑以 $G$ 为系数矩阵的齐次线性方程组：
$$
G \mathbf{x} = \mathbf{0}
\quad \text{即} \quad
\begin{bmatrix}
\sum_{j=1}^m (\alpha_1, \alpha_j)x_j \\
\vdots \\
\sum_{j=1}^m (\alpha_m, \alpha_j)x_j
\end{bmatrix}
=
\begin{bmatrix}
0 \\ \vdots \\ 0
\end{bmatrix}
$$

任取一个解 $\mathbf{x}_0 = (x_{10}, \ldots, x_{m0})^\top$ 满足 $G\mathbf{x}_0 = \mathbf{0}$，则有：

$$
\sum_{j=1}^m (\alpha_i, \alpha_j)x_{j0} = 0, \quad i = 1, \ldots, m
$$

即：
$$
\left( \alpha_i, \sum_{j=1}^m x_{j0} \alpha_j \right) = 0, \quad \forall i = 1,\ldots,m
$$

令 $\beta = \sum_{j=1}^m x_{j0} \alpha_j$，则上式表明：
$$
(\alpha_i, \beta) = 0, \quad \forall i = 1,\ldots,m
$$

又因为 $\alpha_1,\ldots,\alpha_m$ 线性无关，它们张成的空间是 $\text{span}\{\alpha_1,\ldots,\alpha_m\}$，而 $\beta$ 正属于这个空间。

但 $\beta$ 与该空间中所有基向量正交，说明 $\beta = 0$。

因此：
$$
\sum_{j=1}^m x_{j0} \alpha_j = 0
\quad \Rightarrow \quad
x_{j0} = 0, \quad j = 1,\ldots,m
$$

所以 $G\mathbf{x} = \mathbf{0}$ 只有零解，即 $G$ 可逆。

---

### **结论**

$$
\boxed{
\alpha_1, \ldots, \alpha_m \text{ 线性无关} \iff G \text{ 可逆}
}
$$

---

### **补充说明**

- $G$ 称为 **Gram 矩阵**，其元素为向量之间的内积。
- Gram 矩阵总是 **对称半正定** 的。
- 若向量组线性无关，则 $G$ 正定，从而可逆。
- 本题的核心思想是通过内积构造方程组，利用线性无关性推导出唯一零解。
